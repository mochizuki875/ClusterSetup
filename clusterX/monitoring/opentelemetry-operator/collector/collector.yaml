# Reference for spanmetrics
# https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/spanmetricsprocessor/testdata/config.yaml

apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: opentelemetry
  namespace: monitoring
  labels:
    app: opentelemetry
spec:
  mode: deployment
  # args:
  #   log-level: "debug"
  nodeSelector: 
    dedicated: monitoring
  tolerations:
  - key: "dedicated"
    value: "monitoring"
    operator: "Equal"
    effect: "NoSchedule"
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
      otlp/dummy-receiver: # dummy receiver
        protocols:
          grpc:
            endpoint: "localhost:12345"  
    exporters:
      otlp:
        # endpoint: tempo-distributor:4317
        endpoint: tempo:4317
        tls:
          insecure: true

      otlp/dummy-exporter: # dummy exporter
        endpoint: localhost:12345

      prometheusremotewrite: # prometheus remote write
        endpoint: "http://kube-prometheus-stack-prometheus:9090/api/v1/write"
        resource_to_telemetry_conversion:
          enabled: true 

      prometheus/servicegraph:
        endpoint: 0.0.0.0:9090

    processors:
      batch:
        send_batch_size: 1000
        timeout: 5s
      memory_limiter:
        check_interval: 1s
        limit_mib: 4000
        spike_limit_mib: 800
      # tail_sampling:
      #   decision_wait: 10s
      #   num_traces: 100000
      #   policies:
      #     [
      #       {
      #         name: latency_policy,
      #         type: latency,
      #         latency: {threshold_ms: 20}
      #       },
      #     ]
      spanmetrics:
        metrics_exporter: prometheusremotewrite
        dimensions:
          - name: http.method
            default: GET
          - name: http.status_code
        dimensions_cache_size: 1000
        aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE" 

      servicegraph:
        metrics_exporter: prometheus/servicegraph # Exporter to send metrics to
        latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms] # Buckets for latency histogram
        dimensions: [cluster, namespace] # Additional dimensions (labels) to be added to the metrics extracted from the resource and span attributes
        store: # Configuration for the in-memory store
          ttl: 2s # Value to wait for an edge to be completed
          max_items: 200 # Amount of edges that will be stored in the storeMap 

    service:
      pipelines:
        traces:
          receivers:
          - otlp
          processors:
          # - memory_limiter
          # - batch
          # - tail_sampling # metrics生成前に置きたい
          exporters:
          - otlp
        traces/servicegraph:
          receivers:
          - otlp
          processors:
          - spanmetrics
          - servicegraph
          exporters:
          - otlp/dummy-exporter # dummy
        metrics/spanmetrics:
          receivers: 
          - otlp/dummy-receiver # dummy
          exporters:
          - prometheusremotewrite
        metrics/servicegraph:
          receivers: 
          - otlp/dummy-receiver # dummy
          exporters: 
          - prometheus/servicegraph
      telemetry: # デバッグログ
        logs:
          level: "debug"
          
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: opentelemetry-prometheus-exporter
  name: opentelemetry-prometheus-exporter
  namespace: monitoring
spec:
  selector:
    app: opentelemetry
  ports:
  - protocol: TCP
    port: 9090
    targetPort: 9090